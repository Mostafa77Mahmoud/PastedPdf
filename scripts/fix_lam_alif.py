#!/usr/bin/env python3
"""
Fix Lam-Alif ligature issues in Arabic text
============================================

This script fixes common Lam-Alif decomposition errors that occur when 
extracting Arabic text from PDFs:

- ÿßÿ£ŸÑ -> ÿßŸÑÿ£ (fixes: ÿßÿ£ŸÑŸÖŸäŸÜ -> ÿßŸÑÿ£ŸÖŸäŸÜ, ÿßÿ£ŸÑŸÖÿ± -> ÿßŸÑÿ£ŸÖÿ±)
- ÿßÿ•ŸÑ -> ÿßŸÑÿ• (fixes: ÿßÿ•ŸÑÿ¨ÿßÿ±ÿ© -> ÿßŸÑÿ•ÿ¨ÿßÿ±ÿ©, ÿßÿ•ŸÑÿ≥ŸÑÿßŸÖŸäÿ© -> ÿßŸÑÿ•ÿ≥ŸÑÿßŸÖŸäÿ©)
- ÿßÿ¢ŸÑ -> ÿßŸÑÿ¢ (fixes: ÿßÿ¢ŸÑŸÜ -> ÿßŸÑÿ¢ŸÜ, ÿßÿ¢ŸÑŸäÿ© -> ÿßŸÑÿ¢Ÿäÿ©)

These errors happen when PDF stores Lam-Alif ligatures in a way that 
causes incorrect character ordering during extraction.
"""

import re
import sys
from pathlib import Path


def fix_lam_alif(text: str) -> dict:
    """
    Fix Lam-Alif ligature issues in Arabic text
    
    Args:
        text: Input text with Lam-Alif errors
        
    Returns:
        Dictionary with 'text' (fixed text) and 'stats' (replacement counts)
    """
    stats = {
        'ÿßÿ£ŸÑ -> ÿßŸÑÿ£': 0,
        'ÿßÿ•ŸÑ -> ÿßŸÑÿ•': 0,
        'ÿßÿ¢ŸÑ -> ÿßŸÑÿ¢': 0,
        'total_fixes': 0
    }
    
    # Pattern 1: ÿßÿ£ŸÑ -> ÿßŸÑÿ£ (most common - affects ÿßŸÑÿ£ŸÖŸäŸÜ, ÿßŸÑÿ£ŸÖÿ±, ÿßŸÑÿ£ŸàŸÑ, etc.)
    # This fixes the case where Lam and Hamza are reversed
    fixed_text = text
    pattern1_count = len(re.findall(r'ÿ£ŸÑ', fixed_text))
    fixed_text = re.sub(r'ÿ£ŸÑ', 'ŸÑÿ£', fixed_text)
    stats['ÿßÿ£ŸÑ -> ÿßŸÑÿ£'] = pattern1_count
    
    # Pattern 2: ÿßÿ•ŸÑ -> ÿßŸÑÿ• (affects ÿßŸÑÿ•ÿ¨ÿßÿ±ÿ©, ÿßŸÑÿ•ÿ≥ŸÑÿßŸÖŸäÿ©, ÿßŸÑÿ•ŸäŸÖÿßŸÜ, etc.)
    # This fixes the case where Lam and Alif with Hamza below are reversed
    pattern2_count = len(re.findall(r'ÿ•ŸÑ', fixed_text))
    fixed_text = re.sub(r'ÿ•ŸÑ', 'ŸÑÿ•', fixed_text)
    stats['ÿßÿ•ŸÑ -> ÿßŸÑÿ•'] = pattern2_count
    
    # Pattern 3: ÿßÿ¢ŸÑ -> ÿßŸÑÿ¢ (affects ÿßŸÑÿ¢ÿÆÿ±ÿ©, ÿßŸÑÿ¢ŸÜ, ÿßŸÑÿ¢Ÿäÿ©, etc.)
    # This fixes the case where Lam and Alif with Madda are reversed
    pattern3_count = len(re.findall(r'ÿ¢ŸÑ', fixed_text))
    fixed_text = re.sub(r'ÿ¢ŸÑ', 'ŸÑÿ¢', fixed_text)
    stats['ÿßÿ¢ŸÑ -> ÿßŸÑÿ¢'] = pattern3_count
    
    stats['total_fixes'] = pattern1_count + pattern2_count + pattern3_count
    
    return {
        'text': fixed_text,
        'stats': stats
    }


def main():
    """Main function to fix Lam-Alif issues in the output file"""
    
    input_file = Path('output/Shariaah-Standards-ARB_structured.md')
    output_file = input_file  # Overwrite the same file
    backup_file = Path('output/Shariaah-Standards-ARB_structured.md.backup')
    
    print('=' * 80)
    print('üîß FIXING LAM-ALIF LIGATURE ISSUES')
    print('=' * 80)
    print()
    
    # Check if file exists
    if not input_file.exists():
        print(f'‚ùå Error: File not found: {input_file}')
        sys.exit(1)
    
    # Create backup
    print(f'üìÅ Input file: {input_file}')
    print(f'üíæ Creating backup: {backup_file}')
    
    with open(input_file, 'r', encoding='utf-8') as f:
        original_text = f.read()
    
    with open(backup_file, 'w', encoding='utf-8') as f:
        f.write(original_text)
    
    print()
    print('üîç Scanning for Lam-Alif errors...')
    
    # Apply fixes
    result = fix_lam_alif(original_text)
    fixed_text = result['text']
    stats = result['stats']
    
    print()
    print('üìä Replacement Statistics:')
    print('=' * 80)
    print(f"   ÿßÿ£ŸÑ -> ÿßŸÑÿ£ : {stats['ÿßÿ£ŸÑ -> ÿßŸÑÿ£']:,} replacements")
    print(f"   ÿßÿ•ŸÑ -> ÿßŸÑÿ• : {stats['ÿßÿ•ŸÑ -> ÿßŸÑÿ•']:,} replacements")
    print(f"   ÿßÿ¢ŸÑ -> ÿßŸÑÿ¢ : {stats['ÿßÿ¢ŸÑ -> ÿßŸÑÿ¢']:,} replacements")
    print(f"   TOTAL:    {stats['total_fixes']:,} fixes applied")
    print('=' * 80)
    print()
    
    # Save fixed text
    with open(output_file, 'w', encoding='utf-8') as f:
        f.write(fixed_text)
    
    print(f'‚úÖ Fixed file saved: {output_file}')
    print()
    
    # Verify fixes by showing first few TOC lines
    print('üîç VERIFICATION - First TOC entries (after fix):')
    print('=' * 80)
    
    lines = fixed_text.split('\n')
    toc_lines = []
    for line in lines:
        if ('ŸÉŸÑŸÖÿ©' in line or 'ÿßŸÑÿ•ÿ¨ÿßÿ±ÿ©' in line or 'ÿßŸÑÿ£ŸÖŸäŸÜ' in line or 
            'ÿßŸÑÿ¢' in line) and len(line.strip()) > 15:
            if '.' * 3 in line:  # Table of contents line
                toc_lines.append(line.strip())
                if len(toc_lines) >= 10:
                    break
    
    for i, line in enumerate(toc_lines, 1):
        print(f'{i:2}. {line}')
    
    print('=' * 80)
    print()
    
    # Verify no more errors exist
    remaining_errors = []
    if 'ÿßÿ£' in fixed_text:
        remaining_errors.append('ÿßÿ£ still found')
    if 'ÿßÿ•' in fixed_text:
        remaining_errors.append('ÿßÿ• still found')
    if 'ÿßÿ¢' in fixed_text:
        remaining_errors.append('ÿßÿ¢ still found')
    
    if remaining_errors:
        print('‚ö†Ô∏è  WARNING: Some patterns still exist:')
        for error in remaining_errors:
            print(f'   - {error}')
        print()
    else:
        print('‚úÖ ALL LAM-ALIF ERRORS FIXED!')
        print()
    
    print('=' * 80)
    print('üéâ FILE READY FOR GEMINI!')
    print('=' * 80)
    print()
    print(f'Original backup saved at: {backup_file}')
    print()


if __name__ == '__main__':
    main()
