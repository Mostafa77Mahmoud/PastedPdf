
#!/usr/bin/env python3
"""
Deep Text Cleaner - ØªÙ†Ø¸ÙŠÙ Ø¹Ù…ÙŠÙ‚ Ù„Ù„Ù†ØµÙˆØµ Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©
ÙŠØ­Ù„ Ù…Ø´Ø§ÙƒÙ„: Ø§Ù„ØªÙƒØ±Ø§Ø±ØŒ Ø£Ø±Ù‚Ø§Ù… Ø§Ù„ØµÙØ­Ø§Øª Ø§Ù„Ù…ÙƒØ±Ø±Ø©ØŒ Ø§Ù„ÙÙ‡Ø§Ø±Ø³ØŒ Ø§Ù„Ø­ÙˆØ§Ø´ÙŠ Ø§Ù„Ù…Ø¯Ù…Ø¬Ø©ØŒ Ø§Ù„ØªØ±ÙˆÙŠØ³Ø§Øª ÙˆØ§Ù„ØªØ°ÙŠÙŠÙ„Ø§Øª
"""

import re
import sys
from pathlib import Path
from difflib import SequenceMatcher
from collections import Counter


class DeepTextCleaner:
    """Ù…Ù†Ø¸Ù Ù…ØªÙ‚Ø¯Ù… Ù„Ù„Ù†ØµÙˆØµ Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©"""
    
    def __init__(self):
        self.similarity_threshold = 0.90  # Ù†Ø³Ø¨Ø© Ø§Ù„ØªØ´Ø§Ø¨Ù‡ Ù„Ø§Ø¹ØªØ¨Ø§Ø± Ø§Ù„Ø³Ø·Ø± Ù…ÙƒØ±Ø±
        self.min_line_length = 10  # Ø²ÙŠØ§Ø¯Ø© Ø§Ù„Ø­Ø¯ Ø§Ù„Ø£Ø¯Ù†Ù‰ Ù„Ø·ÙˆÙ„ Ø§Ù„Ø³Ø·Ø±
        self.common_headers_footers = [
            r'ïºï»Ÿï»¤ï»Œïºï»³ï»´ïº®\s*ïºï»Ÿïº¸ïº®ï»‹ï»´ïº”',
            r'ïº­ï»—ï»¢\s*ïºï»Ÿïº¼ï»”ïº¤ïº”',
            r'www\.aaoifi\.com',
            r'info@aaoifi\.com',
            r'Â©.*aaoifi',
            r'Ø§Ù„Ù…Ø¹Ø§ÙŠÙŠØ±\s*Ø§Ù„Ø´Ø±Ø¹ÙŠØ©',
            r'Ø±Ù‚Ù…\s*Ø§Ù„ØµÙØ­Ø©',
        ]
        
    def clean_text(self, text: str) -> str:
        """ØªÙ†Ø¸ÙŠÙ Ø´Ø§Ù…Ù„ Ù„Ù„Ù†Øµ"""
        
        lines = text.split('\n')
        print(f"ğŸ“Š Ø¹Ø¯Ø¯ Ø§Ù„Ø£Ø³Ø·Ø± Ø§Ù„Ø£ØµÙ„ÙŠ: {len(lines)}")
        
        # Ø§Ù„Ù…Ø±Ø­Ù„Ø© 1: Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ØªØ±ÙˆÙŠØ³Ø§Øª ÙˆØ§Ù„ØªØ°ÙŠÙŠÙ„Ø§Øª Ø§Ù„Ù…ØªÙƒØ±Ø±Ø©
        lines = self._remove_headers_footers(lines)
        print(f"âœ… Ø¨Ø¹Ø¯ Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ØªØ±ÙˆÙŠØ³Ø§Øª ÙˆØ§Ù„ØªØ°ÙŠÙŠÙ„Ø§Øª: {len(lines)} Ø³Ø·Ø±")
        
        # Ø§Ù„Ù…Ø±Ø­Ù„Ø© 2: Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ØªÙƒØ±Ø§Ø± Ø§Ù„Ù…Ø¨Ø§Ø´Ø±
        lines = self._remove_exact_duplicates(lines)
        print(f"âœ… Ø¨Ø¹Ø¯ Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ØªÙƒØ±Ø§Ø± Ø§Ù„Ù…Ø¨Ø§Ø´Ø±: {len(lines)} Ø³Ø·Ø±")
        
        # Ø§Ù„Ù…Ø±Ø­Ù„Ø© 3: Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ØªÙƒØ±Ø§Ø± Ø§Ù„Ø¶Ø¨Ø§Ø¨ÙŠ (Fuzzy)
        lines = self._remove_fuzzy_duplicates(lines)
        print(f"âœ… Ø¨Ø¹Ø¯ Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ØªÙƒØ±Ø§Ø± Ø§Ù„Ø¶Ø¨Ø§Ø¨ÙŠ: {len(lines)} Ø³Ø·Ø±")
        
        # Ø§Ù„Ù…Ø±Ø­Ù„Ø© 4: ØªÙ†Ø¸ÙŠÙ Ø£Ø±Ù‚Ø§Ù… Ø§Ù„ØµÙØ­Ø§Øª Ø§Ù„Ù…ÙƒØ±Ø±Ø©
        lines = self._clean_page_numbers(lines)
        print(f"âœ… Ø¨Ø¹Ø¯ ØªÙ†Ø¸ÙŠÙ Ø£Ø±Ù‚Ø§Ù… Ø§Ù„ØµÙØ­Ø§Øª: {len(lines)} Ø³Ø·Ø±")
        
        # Ø§Ù„Ù…Ø±Ø­Ù„Ø© 5: Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ÙÙ‡Ø§Ø±Ø³ (Ø§Ù„Ù†Ù‚Ø§Ø· Ø§Ù„Ù…ØªØ¹Ø¯Ø¯Ø©)
        lines = self._remove_toc_lines(lines)
        print(f"âœ… Ø¨Ø¹Ø¯ Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ÙÙ‡Ø§Ø±Ø³: {len(lines)} Ø³Ø·Ø±")
        
        # Ø§Ù„Ù…Ø±Ø­Ù„Ø© 6: ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø­ÙˆØ§Ø´ÙŠ Ø§Ù„Ù…Ø¯Ù…Ø¬Ø©
        lines = self._clean_footnotes(lines)
        print(f"âœ… Ø¨Ø¹Ø¯ ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø­ÙˆØ§Ø´ÙŠ: {len(lines)} Ø³Ø·Ø±")
        
        # Ø§Ù„Ù…Ø±Ø­Ù„Ø© 7: Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ø£Ø³Ø·Ø± Ø§Ù„Ù‚ØµÙŠØ±Ø© Ø¬Ø¯Ø§Ù‹ Ø£Ùˆ Ø§Ù„ÙØ§Ø±ØºØ©
        lines = self._remove_short_lines(lines)
        print(f"âœ… Ø¨Ø¹Ø¯ Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ø£Ø³Ø·Ø± Ø§Ù„Ù‚ØµÙŠØ±Ø©: {len(lines)} Ø³Ø·Ø±")
        
        # Ø§Ù„Ù…Ø±Ø­Ù„Ø© 8: Ø¥ØµÙ„Ø§Ø­ Ø§Ù„Ù…Ø³Ø§ÙØ§Øª ÙˆØ§Ù„ØªÙ†Ø³ÙŠÙ‚
        lines = self._fix_spacing(lines)
        print(f"âœ… Ø¨Ø¹Ø¯ Ø¥ØµÙ„Ø§Ø­ Ø§Ù„Ù…Ø³Ø§ÙØ§Øª: {len(lines)} Ø³Ø·Ø±")
        
        # Ø§Ù„Ù…Ø±Ø­Ù„Ø© 9: Ø¯Ù…Ø¬ Ø§Ù„ÙÙ‚Ø±Ø§Øª Ø§Ù„Ù…ÙƒØ³ÙˆØ±Ø©
        text = '\n'.join(lines)
        text = self._merge_broken_paragraphs(text)
        lines = text.split('\n')
        print(f"âœ… Ø¨Ø¹Ø¯ Ø¯Ù…Ø¬ Ø§Ù„ÙÙ‚Ø±Ø§Øª: {len(lines)} Ø³Ø·Ø±")
        
        # Ø§Ù„Ù…Ø±Ø­Ù„Ø© 10: ØªÙ†Ø¸ÙŠÙ Ù†Ù‡Ø§Ø¦ÙŠ Ù„Ù„Ø£Ø³Ø·Ø± Ø§Ù„ÙØ§Ø±ØºØ© Ø§Ù„Ø²Ø§Ø¦Ø¯Ø©
        lines = self._clean_empty_lines(lines)
        print(f"âœ… Ø§Ù„ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ: {len(lines)} Ø³Ø·Ø±")
        
        return '\n'.join(lines)
    
    def _remove_headers_footers(self, lines: list) -> list:
        """Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ØªØ±ÙˆÙŠØ³Ø§Øª ÙˆØ§Ù„ØªØ°ÙŠÙŠÙ„Ø§Øª Ø§Ù„Ù…ØªÙƒØ±Ø±Ø©"""
        
        cleaned = []
        
        for line in lines:
            line_stripped = line.strip()
            
            # ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø£Ù†Ù…Ø§Ø· Ø§Ù„Ø´Ø§Ø¦Ø¹Ø©
            is_header_footer = False
            for pattern in self.common_headers_footers:
                if re.search(pattern, line_stripped, re.IGNORECASE):
                    is_header_footer = True
                    break
            
            # Ø§Ø­ØªÙØ¸ Ø¨Ø§Ù„Ø³Ø·Ø± ÙÙ‚Ø· Ø¥Ø°Ø§ Ù„Ù… ÙŠÙƒÙ† ØªØ±ÙˆÙŠØ³Ø© Ø£Ùˆ ØªØ°ÙŠÙŠÙ„
            if not is_header_footer:
                cleaned.append(line)
        
        return cleaned
    
    def _remove_exact_duplicates(self, lines: list) -> list:
        """Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ø£Ø³Ø·Ø± Ø§Ù„Ù…ÙƒØ±Ø±Ø© Ø¨Ø´ÙƒÙ„ Ù…Ø¨Ø§Ø´Ø± Ù…ØªØªØ§Ù„ÙŠØ©"""
        
        cleaned = []
        prev_line = None
        
        for line in lines:
            line = line.strip()
            
            # Ù„Ø§ ØªØ¶ÙŠÙ Ø§Ù„Ø³Ø·Ø± Ø¥Ø°Ø§ ÙƒØ§Ù† Ù…Ø·Ø§Ø¨Ù‚ ØªÙ…Ø§Ù…Ø§Ù‹ Ù„Ù„Ø³Ø·Ø± Ø§Ù„Ø³Ø§Ø¨Ù‚
            if line != prev_line:
                cleaned.append(line)
                prev_line = line
        
        return cleaned
    
    def _remove_fuzzy_duplicates(self, lines: list) -> list:
        """Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ø£Ø³Ø·Ø± Ø§Ù„Ù…ØªØ´Ø§Ø¨Ù‡Ø© Ø¬Ø¯Ø§Ù‹ (>90%)"""
        
        cleaned = []
        prev_line = None
        
        for line in lines:
            if not line.strip():
                continue
            
            # Ù‚Ø§Ø±Ù† Ù…Ø¹ Ø§Ù„Ø³Ø·Ø± Ø§Ù„Ø³Ø§Ø¨Ù‚
            if prev_line:
                similarity = SequenceMatcher(None, line, prev_line).ratio()
                
                # Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„ØªØ´Ø§Ø¨Ù‡ Ø£ÙƒØ«Ø± Ù…Ù† 90%ØŒ ØªØ¬Ø§Ù‡Ù„ Ø§Ù„Ø³Ø·Ø±
                if similarity >= self.similarity_threshold:
                    continue
            
            cleaned.append(line)
            prev_line = line
        
        return cleaned
    
    def _clean_page_numbers(self, lines: list) -> list:
        """Ø¥Ø²Ø§Ù„Ø© Ø£Ø±Ù‚Ø§Ù… Ø§Ù„ØµÙØ­Ø§Øª Ø§Ù„Ù…ÙƒØ±Ø±Ø© ÙˆØ§Ù„Ù…Ø´ÙˆÙ‡Ø©"""
        
        cleaned = []
        
        # Patterns Ù„Ø£Ø±Ù‚Ø§Ù… Ø§Ù„ØµÙØ­Ø§Øª Ø§Ù„Ù…Ø´ÙˆÙ‡Ø©
        page_number_patterns = [
            r'^[\u0660-\u0669]{2,4}\s+[\u0660-\u0669]{2,4}$',  # Ù¥Ù¡Ù¥Ù¡ Ù¥Ù¡Ù¥Ù¡
            r'^[\u0660-\u0669]{3,}$',  # Ù£Ù Ù¢Ù£Ù Ù¢
            r'^\d{3,}$',  # 302302
            r'^[\u0660-\u0669]{1,3}$',  # Ø£Ø±Ù‚Ø§Ù… Ø¹Ø±Ø¨ÙŠØ© Ù…Ù†ÙØ±Ø¯Ø© Ù‚ØµÙŠØ±Ø©
            r'^\d+-\d+$',  # Ø£Ø±Ù‚Ø§Ù… Ù…Ø«Ù„ 1-85
            r'^\d+$',  # Ø£Ø±Ù‚Ø§Ù… Ù…Ù†ÙØ±Ø¯Ø©
            r'^[\u0660-\u0669]+\s*-\s*[\u0660-\u0669]+$',  # Ù¡-Ù¨Ù¥
        ]
        
        for line in lines:
            line_stripped = line.strip()
            
            # ØªØ­Ù‚Ù‚ Ù…Ù† Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù€ patterns
            is_page_number = False
            for pattern in page_number_patterns:
                if re.match(pattern, line_stripped):
                    is_page_number = True
                    break
            
            # Ø§Ø­ØªÙØ¸ Ø¨Ø§Ù„Ø³Ø·Ø± ÙÙ‚Ø· Ø¥Ø°Ø§ Ù„Ù… ÙŠÙƒÙ† Ø±Ù‚Ù… ØµÙØ­Ø©
            if not is_page_number:
                cleaned.append(line)
        
        return cleaned
    
    def _remove_toc_lines(self, lines: list) -> list:
        """Ø¥Ø²Ø§Ù„Ø© Ø£Ø³Ø·Ø± Ø§Ù„ÙÙ‡Ø±Ø³ (Ø§Ù„ØªÙŠ ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ù†Ù‚Ø§Ø· Ù…ØªØ¹Ø¯Ø¯Ø©)"""
        
        cleaned = []
        
        for line in lines:
            # Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ø³Ø·Ø± ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ 5 Ù†Ù‚Ø§Ø· Ù…ØªØªØ§Ù„ÙŠØ© Ø£Ùˆ Ø£ÙƒØ«Ø±ØŒ Ø§Ø­Ø°ÙÙ‡
            if not re.search(r'\.{5,}', line):
                cleaned.append(line)
        
        return cleaned
    
    def _clean_footnotes(self, lines: list) -> list:
        """ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø­ÙˆØ§Ø´ÙŠ Ø§Ù„Ø³ÙÙ„ÙŠØ© Ø§Ù„Ù…Ø¯Ù…Ø¬Ø©"""
        
        cleaned = []
        
        # Pattern Ù„Ù„Ø­ÙˆØ§Ø´ÙŠ: (1) Ø£Ùˆ .(Ù¡) Ø£Ùˆ Ù…Ø±Ø§Ø¬Ø¹ Ù…ÙƒØ±Ø±Ø©
        footnote_pattern = r'\(\s*[\u0660-\u0669\d]+\s*\)|\.\(\s*[\u0660-\u0669\d]+\s*\)'
        
        for line in lines:
            # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ø­ÙˆØ§Ø´ÙŠ Ø§Ù„Ù…ÙƒØ±Ø±Ø© Ù…Ù† Ù…Ù†ØªØµÙ Ø§Ù„Ø³Ø·Ø±
            line_cleaned = re.sub(footnote_pattern + r'\s*' + footnote_pattern, '', line)
            
            # Ø¥Ø²Ø§Ù„Ø© Ø£Ø³Ø·Ø± ØªØ­ØªÙˆÙŠ ÙÙ‚Ø· Ø¹Ù„Ù‰ Ù…Ø±Ø§Ø¬Ø¹ (Ù…Ø«Ù„: .(Ù¢Ù¨Ù¢ Ù¢Ù¨Ù¢) :ïºï»µï»³ïº”)
            if re.match(r'^\s*[\.\(\)\s\u0660-\u0669\d:]+\s*$', line_cleaned):
                continue
            
            cleaned.append(line_cleaned)
        
        return cleaned
    
    def _remove_short_lines(self, lines: list) -> list:
        """Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ø£Ø³Ø·Ø± Ø§Ù„Ù‚ØµÙŠØ±Ø© Ø¬Ø¯Ø§Ù‹ (Ø£Ù‚Ù„ Ù…Ù† 10 Ø£Ø­Ø±Ù)"""
        
        cleaned = []
        
        for line in lines:
            # Ø§Ø­ØªÙØ¸ ÙÙ‚Ø· Ø¨Ø§Ù„Ø£Ø³Ø·Ø± Ø§Ù„ØªÙŠ ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ù…Ø­ØªÙˆÙ‰ Ø­Ù‚ÙŠÙ‚ÙŠ
            if len(line.strip()) >= self.min_line_length:
                cleaned.append(line)
        
        return cleaned
    
    def _fix_spacing(self, lines: list) -> list:
        """Ø¥ØµÙ„Ø§Ø­ Ø§Ù„Ù…Ø³Ø§ÙØ§Øª Ø§Ù„Ø²Ø§Ø¦Ø¯Ø©"""
        
        cleaned = []
        
        for line in lines:
            # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ù…Ø³Ø§ÙØ§Øª Ø§Ù„Ù…ØªØ¹Ø¯Ø¯Ø©
            line = re.sub(r'\s+', ' ', line)
            
            # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ù…Ø³Ø§ÙØ§Øª Ù…Ù† Ø¨Ø¯Ø§ÙŠØ© ÙˆÙ†Ù‡Ø§ÙŠØ© Ø§Ù„Ø³Ø·Ø±
            line = line.strip()
            
            if line:
                cleaned.append(line)
        
        return cleaned
    
    def _merge_broken_paragraphs(self, text: str) -> str:
        """Ø¯Ù…Ø¬ Ø§Ù„ÙÙ‚Ø±Ø§Øª Ø§Ù„Ù…ÙƒØ³ÙˆØ±Ø© - Ø§Ù„Ø£Ø³Ø·Ø± Ø§Ù„ØªÙŠ Ù„Ø§ ØªÙ†ØªÙ‡ÙŠ Ø¨Ø¹Ù„Ø§Ù…Ø§Øª ØªØ±Ù‚ÙŠÙ…"""
        
        # Ø¯Ù…Ø¬ Ø§Ù„Ø£Ø³Ø·Ø± Ø¥Ø°Ø§ Ù„Ù… ØªÙ†ØªÙ‡Ù Ø¨Ù†Ù‚Ø·Ø© Ø£Ùˆ ÙØ§ØµÙ„Ø© Ø£Ùˆ Ø¹Ù„Ø§Ù…Ø© Ø§Ø³ØªÙÙ‡Ø§Ù… Ø£Ùˆ ØªØ¹Ø¬Ø¨ Ø£Ùˆ Ù†Ù‚Ø·ØªÙŠÙ†
        # ÙˆÙ„ÙƒÙ† Ø§Ø­ØªÙØ¸ Ø¨Ø§Ù„Ø£Ø³Ø·Ø± Ø§Ù„ØªÙŠ ØªÙ†ØªÙ‡ÙŠ Ø¨Ù‡Ø°Ù‡ Ø§Ù„Ø¹Ù„Ø§Ù…Ø§Øª ÙƒÙÙˆØ§ØµÙ„ ÙÙ‚Ø±Ø§Øª
        text = re.sub(r'([^\.\:\Ø›\!\?\n])\n', r'\1 ', text)
        
        # Ø¥ØµÙ„Ø§Ø­ Ø§Ù„Ù…Ø³Ø§ÙØ§Øª Ø§Ù„Ù…ØªØ¹Ø¯Ø¯Ø© Ø§Ù„Ù†Ø§ØªØ¬Ø© Ø¹Ù† Ø§Ù„Ø¯Ù…Ø¬
        text = re.sub(r' +', ' ', text)
        
        return text
    
    def _clean_empty_lines(self, lines: list) -> list:
        """ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø£Ø³Ø·Ø± Ø§Ù„ÙØ§Ø±ØºØ© Ø§Ù„Ø²Ø§Ø¦Ø¯Ø© - Ø§Ø­ØªÙØ¸ Ø¨Ø³Ø·Ø± ÙØ§Ø±Øº ÙˆØ§Ø­Ø¯ ÙÙ‚Ø· Ø¨ÙŠÙ† Ø§Ù„ÙÙ‚Ø±Ø§Øª"""
        
        cleaned = []
        prev_empty = False
        
        for line in lines:
            is_empty = not line.strip()
            
            if is_empty:
                # Ø£Ø¶Ù Ø³Ø·Ø± ÙØ§Ø±Øº ÙˆØ§Ø­Ø¯ ÙÙ‚Ø·
                if not prev_empty:
                    cleaned.append('')
                prev_empty = True
            else:
                cleaned.append(line)
                prev_empty = False
        
        return cleaned


def main():
    """Ù†Ù‚Ø·Ø© Ø§Ù„Ø¯Ø®ÙˆÙ„ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©"""
    
    if len(sys.argv) < 2:
        print("Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…: python3 scripts/deep_text_cleaner.py <input_file.txt>")
        print("Ù…Ø«Ø§Ù„: python3 scripts/deep_text_cleaner.py output/Shariaah-Standards-ARB_cleaned.txt")
        return 1
    
    input_path = Path(sys.argv[1])
    
    if not input_path.exists():
        print(f"âŒ Ø§Ù„Ù…Ù„Ù ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯: {input_path}")
        return 1
    
    print("=" * 70)
    print("ğŸ§¹ Ù…Ù†Ø¸Ù Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„Ù…ØªÙ‚Ø¯Ù… - Deep Text Cleaner v2.0")
    print("=" * 70)
    print()
    
    # Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ù…Ù„Ù
    print(f"ğŸ“– Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ù…Ù„Ù: {input_path}")
    with open(input_path, 'r', encoding='utf-8') as f:
        original_text = f.read()
    
    print(f"ğŸ“Š Ø­Ø¬Ù… Ø§Ù„Ù†Øµ Ø§Ù„Ø£ØµÙ„ÙŠ: {len(original_text):,} Ø­Ø±Ù")
    print()
    
    # Ø§Ù„ØªÙ†Ø¸ÙŠÙ
    cleaner = DeepTextCleaner()
    cleaned_text = cleaner.clean_text(original_text)
    
    print()
    print(f"ğŸ“Š Ø­Ø¬Ù… Ø§Ù„Ù†Øµ Ø§Ù„Ù†Ø¸ÙŠÙ: {len(cleaned_text):,} Ø­Ø±Ù")
    print(f"ğŸ¯ Ù†Ø³Ø¨Ø© Ø§Ù„Ø¶ØºØ·: {(1 - len(cleaned_text)/len(original_text)) * 100:.1f}%")
    print()
    
    # Ø­ÙØ¸ Ø§Ù„Ù†ØªÙŠØ¬Ø©
    output_path = input_path.parent / f"{input_path.stem}_ultra_clean.txt"
    
    with open(output_path, 'w', encoding='utf-8') as f:
        f.write(cleaned_text)
    
    print(f"âœ… ØªÙ… Ø§Ù„Ø­ÙØ¸ ÙÙŠ: {output_path}")
    print()
    
    # Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø¥Ø¶Ø§ÙÙŠØ©
    print("=" * 70)
    print("ğŸ“Š Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©")
    print("=" * 70)
    print(f"Ø¹Ø¯Ø¯ Ø§Ù„Ø£Ø­Ø±Ù Ø§Ù„Ø£ØµÙ„ÙŠ: {len(original_text):,}")
    print(f"Ø¹Ø¯Ø¯ Ø§Ù„Ø£Ø­Ø±Ù Ø§Ù„Ù†Ø¸ÙŠÙ: {len(cleaned_text):,}")
    print(f"ØªÙ… Ø¥Ø²Ø§Ù„Ø©: {len(original_text) - len(cleaned_text):,} Ø­Ø±Ù")
    print(f"Ø¹Ø¯Ø¯ Ø§Ù„Ø£Ø³Ø·Ø± Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©: {len(cleaned_text.split(chr(10))):,}")
    print()
    print("ğŸ’¡ Ø§Ù„Ù…Ù„Ù Ø¬Ø§Ù‡Ø² Ø§Ù„Ø¢Ù† Ù„Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù…Ø¹ Gemini File Search")
    print()
    
    return 0


if __name__ == '__main__':
    sys.exit(main())
